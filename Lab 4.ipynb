{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zMufu2Vp-z78"},"outputs":[],"source":["!pip install transformers\n","!pip install -U sentence-transformers"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1666807491127,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"7QLOWFocDsY4"},"outputs":[],"source":["# Importing packages\n","import requests\n","import pandas as pd\n","from PIL import Image\n","from urllib import request\n","from sentence_transformers import SentenceTransformer, util\n","from io import BytesIO\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from collections import defaultdict\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.keras.callbacks import ModelCheckpoint\n","from keras.layers.core import Dense, Dropout\n","from keras import layers, Input, Model\n","from keras import backend as K\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.utils import load_img, img_to_array, to_categorical\n","from keras.initializers import Constant\n","from keras.models import Sequential, Model\n","from keras.layers import Concatenate\n","from keras.layers import Dense, Embedding, LSTM, Concatenate as Merge, Reshape, Dropout, Convolution2D, MaxPooling2D, ZeroPadding2D, Flatten\n","from keras.optimizers import Adam\n","import keras_preprocessing\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import average_precision_score\n","import torch\n","from transformers import BertTokenizer,BertModel,LxmertModel,LxmertTokenizer,BartModel,BartTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpjboDOL_RbV"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Dataset splitting\n","img_dir = \"https://vizwiz.cs.colorado.edu//VizWiz_visualization_img/\"\n","split_train = \"train\"\n","annotation_file_train = \"https://vizwiz.cs.colorado.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split_train\n","print(annotation_file_train)\n","split_test = \"test\"\n","annotation_file_test = \"https://vizwiz.cs.colorado.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split_test\n","print(annotation_file_test)\n","split_val = \"val\"\n","annotation_file_val = \"https://vizwiz.cs.colorado.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split_val\n","print(annotation_file_val)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2251,"status":"ok","timestamp":1666801576616,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"Y0H0p8JQACr8"},"outputs":[],"source":["split_data = requests.get(annotation_file_train, allow_redirects=True)\n","data_train = split_data.json()\n","\n","split_data = requests.get(annotation_file_test, allow_redirects=True)\n","data_test = split_data.json()\n","\n","split_data = requests.get(annotation_file_val, allow_redirects=True)\n","data_val = split_data.json()"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":30188,"status":"ok","timestamp":1666806731579,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"UTChVRCDAM44"},"outputs":[],"source":["st_model = SentenceTransformer('sentence-transformers/distilbert-base-nli-mean-tokens')\n","embeddings = st_model.encode(data_train[0]['question'])\n","\n","#Bert sentence transformers\n","def sentence_extractor(sentence):\n","  return st_model.encode(sentence)\n","\n","#VIT extractor\n","VITmodel = SentenceTransformer('clip-ViT-L-14')\n","def VIT_extract_Img(image_name):\n","  res = request.urlopen(image_name).read()\n","  img = Image.open(BytesIO(res))\n","  img_emb = VITmodel.encode(img)\n","  img_emb = np.array(img_emb)\n","  return img_emb\n","\n","#Encode text descriptions\n","def VIT_extract_lang(question):\n","  text_emb = VITmodel.encode(question)\n","  return text_emb\n","\n","def extract_question_features(questions):\n","  inputs=tokenizer(questions,return_tensors=\"pt\")\n","  output=bert(**inputs)\n","  language_feature=output.pooler_output\n","  return language_feature\n","\n","def resize(image_url):\n","  res = request.urlopen(image_url).read()\n","  img = Image.open(BytesIO(res)).resize((224,224))\n","  return img\n","\n","vggmodel = VGG16(weights='imagenet', include_top=True)\n","#model.summary()\n","vgg_model = Model(inputs = vggmodel.inputs, outputs = vggmodel.layers[-2].output )\n","def image_extract(img):\n","  img_data = img_to_array(img)\n","  img_data = np.expand_dims(img_data, axis=0)\n","  img_data = preprocess_input(img_data)\n","  feature_maps = vgg_model.predict(img_data)\n","  return feature_maps"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58891,"status":"ok","timestamp":1666806795029,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"K1MUPa3cDdt4","outputId":"d55d1792-67ac-4968-bf21-b51459b9bf86"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 749ms/step\n","[-0.94377875 -0.41452673 -0.69359535 ...  0.          0.\n","  0.        ]\n","VizWiz_train_00000000.jpg\n","1/1 [==============================] - 1s 613ms/step\n","[-0.89090514 -0.37024656 -0.6383059  ...  0.15287846  0.\n","  1.194839  ]\n","VizWiz_train_00000001.jpg\n","1/1 [==============================] - 1s 603ms/step\n","[-0.95164216 -0.51667565 -0.97550666 ...  0.          1.3009968\n","  0.15316188]\n","VizWiz_train_00000002.jpg\n","1/1 [==============================] - 1s 591ms/step\n","[-0.9272516  -0.39783087 -0.6313059  ...  0.          0.\n","  5.547513  ]\n","VizWiz_train_00000003.jpg\n","Train Shape:  (4, 4864) (4, 13) (4,)\n","1/1 [==============================] - 1s 589ms/step\n","[-0.8113056  -0.38658386 -0.86514163 ...  0.          0.\n","  1.7918983 ]\n","VizWiz_val_00000000.jpg\n","1/1 [==============================] - 1s 604ms/step\n","[-0.88212967 -0.40676525 -0.52065223 ...  0.          0.\n","  4.909209  ]\n","VizWiz_val_00000001.jpg\n","1/1 [==============================] - 1s 591ms/step\n","[-0.92578334 -0.40315208 -0.689809   ...  0.          1.3171558\n","  2.2084641 ]\n","VizWiz_val_00000002.jpg\n","1/1 [==============================] - 1s 595ms/step\n","[-0.8683339  -0.19161084  0.0600514  ...  0.          0.89025486\n","  1.3195412 ]\n","VizWiz_val_00000003.jpg\n","Val Shape:  (4, 4864) (4, 15) (4,)\n","1/1 [==============================] - 1s 606ms/step\n","[-0.9441264 -0.3928359 -0.8742506 ...  1.7149589  0.         2.2841873]\n","VizWiz_test_00000000.jpg\n","1/1 [==============================] - 1s 595ms/step\n","[-0.9636999  -0.41657716 -0.8599354  ...  0.51313794  0.\n","  1.3624685 ]\n","VizWiz_test_00000001.jpg\n","1/1 [==============================] - 1s 584ms/step\n","[-0.9490643  -0.31712022 -0.66186345 ...  0.          0.\n","  1.474984  ]\n","VizWiz_test_00000002.jpg\n","1/1 [==============================] - 1s 591ms/step\n","[-0.9636999  -0.41657716 -0.8599354  ...  0.          0.\n","  1.1489403 ]\n","VizWiz_test_00000003.jpg\n"]}],"source":["count=0\n","temp = [data_train,data_val,data_test]\n","for i in range(len(temp)):\n","  X = [] #feats\n","  y = [] #labels\n","  images_features=[]\n","  language_features=[]\n","  language_features_sen=[]\n","  all_possible_answers=set()\n","  X_VIT=[]\n","  y_b = []\n","  frequent_dict=defaultdict(int)\n","  for vq in temp[i]:\n","    if(len(X))==4:\n","      break\n","\n","    if i !=2:\n","      answers = vq['answers']\n","      all_answers=defaultdict(int)\n","\n","      for answer in answers:\n","        all_answers[answer['answer'].lower()]+=1\n","\n","      all_answers=sorted(all_answers.items(),key=lambda x:x[1],reverse=True)\n","      if frequent_dict.get(all_answers[0][0],0)>=3:\n","\n","        continue\n","      else:\n","        frequent_dict[all_answers[0][0]]+=1\n","\n","      label = vq['answerable']\n","      y_b.append(label)\n","    \n","    # Extract features describing the image\n","    image_name = vq['image']\n","    image_url = img_dir + image_name\n","\n","    img_emb=VIT_extract_Img(image_url)\n","    question = vq['question']\n","    q_emb=VIT_extract_lang(question)\n","\n","    img = resize(image_url)\n","    image_feature= image_extract(img)\n","    images_features.append(image_feature)\n","\n","    # Extract features describing the question\n","    question = vq['question']\n","    question_feature_sen = sentence_extractor(question)\n","    question_feature = extract_question_features(question).detach().numpy()\n","    language_features.append(question_feature)\n","    language_features_sen.append(question_feature_sen)\n","\n","    # Multimodal feature representing both question and image (e.g. concatenate, multiply, etc.)\n","    multimodal_features = np.concatenate((question_feature, image_feature),axis=None)\n","    print(multimodal_features)\n","    VIT_mul_feature=np.concatenate((img_emb,q_emb),axis=None)\n","    # Prepare features and labels\n","    X.append(multimodal_features)\n","    X_VIT.append(VIT_mul_feature)\n","\n","    if i !=2:\n","      try:\n","        top_n=5 if len(all_answers)>=5 else len(all_answers)\n","      except:\n","        print(all_answers)   \n","  \n","      answer_set=set(list( x[0] for x in all_answers)[:top_n])\n","      all_possible_answers=all_possible_answers.union(answer_set)\n","      gold_label = all_answers[0][0]\n","      y.append(gold_label)\n","\n","    print(image_name)\n","\n","  if i == 0:\n","    y_b_train = np.array(y_b)\n","    X_train = np.array(X)\n","    y_train = y\n","    \n","    images_features_train = images_features\n","    language_features_train = language_features\n","    language_features_sen_train = language_features_sen\n","\n","    X_VIT_train = X_VIT\n","    encoder=LabelEncoder()\n","    all_possible_answers=list(set(all_possible_answers))\n","    answers_set=encoder.fit_transform(all_possible_answers)\n","    y_train = encoder.transform(y_train)\n","    train_labels = to_categorical(y_train,num_classes=len(all_possible_answers))\n","    y_train = np.array(train_labels)\n","    print(\"Train Shape: \", X_train.shape, y_train.shape, y_b_train.shape)\n","\n","  if i == 1:\n","    y_b_val = np.array(y_b)\n","    X_val = np.array(X)\n","    y_val = y\n","    images_features_val = images_features\n","    language_features_val = language_features\n","    language_features_sen_val = language_features_sen\n","    X_VIT_val = X_VIT\n","    encoder=LabelEncoder()\n","    all_possible_answers=list(set(all_possible_answers))\n","    answers_set=encoder.fit_transform(all_possible_answers)\n","    y_val = encoder.transform(y_val)\n","    val_labels = to_categorical(y_val,num_classes=len(all_possible_answers))\n","    y_val = np.array(val_labels)\n","    print(\"Val Shape: \", X_val.shape, y_val.shape, y_b_val.shape)\n","\n","  if i == 2:\n","    X_test = np.array(X)\n","\n","    images_features_test = images_features\n","    language_features_test = language_features\n","    language_features_sen_test = language_features_sen\n","    X_VIT_test = X_VIT"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1666804850600,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"lHuy6Gy3E16E","outputId":"d2ccff68-2444-453c-acf4-e4d68c496357"},"outputs":[{"name":"stdout","output_type":"stream","text":["(768,)\n","(4, 1536)\n","(768,) (768,)\n"]}],"source":["# Math definitions\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","print(embeddings.shape)\n","X_VIT_train = np.array(X_VIT_train)\n","print(X_VIT_train.shape)\n","print(img_emb.shape,q_emb.shape)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42967,"status":"ok","timestamp":1666807087070,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"ZJdpYFuYVnvq","outputId":"9c260d93-c60c-4cdf-8c28-68f2ebe95e92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00001: val_loss improved from inf to 0.00000, saving model to SimpleRNN_EM_model.h1\n","1/1 [==============================] - 27s 27s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 2/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00002: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 3/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00003: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 4/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00004: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 5/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00005: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 6/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00006: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 7/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00007: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 8/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00008: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 9/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00009: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 10/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00010: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 11/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00011: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 12/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00012: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 13/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00013: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 54ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 14/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00014: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 15/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00015: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 16/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00016: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 17/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00017: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 18/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00018: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 50ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 19/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00019: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n","Epoch 20/20\n","1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n","Epoch 00020: val_loss did not improve from 0.00000\n","1/1 [==============================] - 0s 55ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 0.7500\n"]}],"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_dim=(4864)))\n","\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.1))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='softmax'))\n","\n","filepath = \"SimpleRNN_EM_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]\n","opt = tf.keras.optimizers.Adam(learning_rate=1e-05)\n","model.compile(loss='categorical_crossentropy',\n","optimizer=opt,\n","metrics=['accuracy'])\n","hist=model.fit(X_train,y_b_train,epochs=20,batch_size=128,validation_data=(X_val, y_b_val),callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":701,"status":"ok","timestamp":1666807906679,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"wT1x7pNqfTgG","outputId":"c7a82e98-de26-4514-e622-556ec808939e"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 127ms/step\n"]}],"source":["results = model.predict(X_test)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1666808092456,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"8hO3KJjqgO-c","outputId":"c8a9de39-4aed-4731-a907-6237d01a5848"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 110ms/step\n","0.0\n"]}],"source":["#predict the test and convert the idnex to the label class\n","result=model.predict(X_test)\n","y_test_pred = np.argmax(result, axis=1)\n","# y_test_gold= np.argmax(y_val, axis=1)\n","result=encoder.inverse_transform(y_test_pred)\n","print(list(result).count('unanswerable')/500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"boK_7VqBhqPx"},"outputs":[],"source":["gtlist = [x['answerable'] for x in data_train]\n","\n","# Save the accuracies\n","acc_list = []\n","i = 0\n","\n","# Compute accuracy for each image\n","for pred in result:\n","\n","    # Get the GT answer list and preprocess\n","    gt_ans = gtlist[i] \n","    gt_ans = [x['answer'] for x in gt_ans]\n","    gt_ans = [x.lower() for x in gt_ans]\n","\n","    # Compute accuracy (compare with at least 3 human answers)\n","    cur_acc = np.minimum(1.0, gt_ans.count(pred)/3.0)\n","\n","    acc_list.append(cur_acc)\n","    i +=1\n","\n","print ('Accuracy: {}'.format(round(np.mean(acc_list), 2)))"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":495,"status":"error","timestamp":1666808360197,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"},"user_tz":300},"id":"4w-d9dW9gs99","outputId":"d84ce8b2-d8f7-43d9-c23c-ad5f142843a1"},"outputs":[{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-aa9502a1822d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"]}],"source":["#All answers\n","gtlist = [x['answerable'] for x in data_train]\n","\n","#save the scores\n","y_test = []\n","pred = []\n","\n","for i in range(0, 1000):\n","  y_test.append(gtlist[i])\n","  pred.append(results[i])\n","\n","y_test = np.array(y_test)\n","pred = np.array(pred)\n","\n","average_precision = average_precision_score(y_test, pred)\n","\n","print(\"AP: {}\".format(round(100*average_precision, 4)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEFSkZQPp_hj"},"outputs":[],"source":["embedding_model = Sequential()\n","embedding_model.add(Embedding(X_VIT_train.shape[0], X_VIT_train.shape[1], embeddings_initializer = Constant(X_VIT_train),\ttrainable = False))\n","\n","image_model = Sequential()\n","image_model.add(Dense(X_VIT_train.shape[1],input_dim=4864,activation='linear'))\n","image_model.add(Reshape((1,X_VIT_train.shape[1])))\n","\n","main_model = Sequential()\n","main_model.add(Concatenate([image_model,embedding_model]))\n","main_model.add(LSTM(1001))\n","main_model.add(Dropout(0.5))\n","main_model.add(Dense(1001,activation='sigmoid'))\n","\n","# Compile and summarize model\n","main_model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = [\"accuracy\",f1_m,precision_m, recall_m])\n","# main_model.summary()\n","\n","# Train/save best model\n","filepath = \"SimpleRNN_EM_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', mode = \"min\", verbose =1, save_best_only = True)\n","\n","print(X_train.shape,y_b_train.shape,X_val.shape,y_b_val.shape)\n","\n","hist=main_model.fit(X_train,y_b_train,epochs=20,batch_size=128,validation_data=(X_val, y_b_val),callbacks = [checkpoint],verbose = 1 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-CZ54tHfsxC"},"outputs":[],"source":["EMBEDDING_SIZE = 500\n","embedding_layer = Embedding(int(X_VIT_train.shape[1]/2), int(X_VIT_train.shape[1]/2),embeddings_initializer= Constant(int(X_VIT_train.shape[1]/2)),trainable=False)\n","\n","int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n","embedded_sequences = embedding_layer(int_sequences_input)\n","x = layers.Bidirectional(layers.SimpleRNN(100, return_sequences=True))(embedded_sequences)\n","x = layers.Bidirectional(layers.SimpleRNN(100))(x)\n","preds = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = Model(int_sequences_input, preds)\n","\n","# summarize the model\n","model.summary()\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = [\"accuracy\",f1_m,precision_m, recall_m])\n","\n","# Train and save the best model\n","filepath = \"SimpleRNN_EM_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', mode = \"min\", verbose =1, save_best_only = True)\n","\n","print(X_train.shape,y_b_train.shape,X_val.shape,y_b_val.shape)\n","\n","hist=model.fit(X_train,y_b_train,epochs=20,batch_size=128,validation_data=(X_val, y_b_val),callbacks = [checkpoint],verbose = 1 )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORfhojhUfySp"},"outputs":[],"source":["#predict the test and convert the idnex to the label class\n","print(X_test)\n","result=model.predict(X_test)\n","y_test_pred = np.argmax(result, axis=1)\n","y_test_gold= np.argmax(y_val, axis=1)\n","result=encoder.inverse_transform(y_test_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4MNa4ZpTk5u"},"outputs":[],"source":["# convert the text feature into discrete value\n","encoder=LabelEncoder()\n","# all_possible_answers=list(all_possible_answers)\n","all_possible_answers=list(set(all_possible_answers))\n","answers_set=encoder.fit_transform(all_possible_answers)\n","y_train=encoder.transform(y_train)\n","y_val=encoder.transform(y_val)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1BX3-9OiAuia11EXDIuewZ5vkSls4Hzlk","timestamp":1666800008319}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10 (default, Mar 15 2022, 12:22:08) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
