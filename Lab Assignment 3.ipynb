{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1alxkFwpJUjf7VNLePYJMuBvJ990nIrqg","timestamp":1665352289914}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usqJ1erBWhtJ","executionInfo":{"status":"ok","timestamp":1665478856919,"user_tz":300,"elapsed":2193,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"480ec805-5d27-45b4-b85d-489a3ff6f734"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","#import tensorflow_model_analysis as tfma\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint\n","#from keras.models import Sequential\n","#from keras.layers.embeddings import Embedding\n","from keras.layers import TextVectorization\n","from keras.layers import Embedding, Dense, Dropout, Flatten, GRU, Input, LSTM, SimpleRNN\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data = pd.read_csv('/content/drive/My Drive/spam.csv', encoding= 'latin_1')"]},{"cell_type":"code","source":["data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)\n","data.rename(columns={'v1': 'Target', 'v2': 'Email'}, inplace=True)\n","data['Target']=data['Target'].map({'ham': 0, 'spam': 1})\n","data.head()\n","\n","texts = data['Email']\n","labels = data['Target']\n","\n","print(\"Text count: \" , len(texts))\n","print(\"Label count: \", len(labels))\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(texts)\n","email_sequences = tokenizer.texts_to_sequences(texts)\n","email_sequences = sorted(email_sequences, key=len)\n","\n","word_index = tokenizer.word_index\n","print(\"{0} unique words found\".format(len(word_index)))\n","\n","#padded_emails = pad_sequences(email_sequences)\n","\n","#print(\"Shape of data: \", padded_emails.shape)\n","#print(padded_emails)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8DuJJ5z-qh-","executionInfo":{"status":"ok","timestamp":1665478859317,"user_tz":300,"elapsed":208,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"462cfc6f-6ef5-4c20-b87c-f26f95c27899"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Text count:  5572\n","Label count:  5572\n","8920 unique words found\n"]}]},{"cell_type":"code","source":["#Data splitting\n","X_train, x_test, Y_train, y_test = train_test_split(email_sequences, labels, test_size=0.3, random_state=7)\n","\n","X_train = pad_sequences(X_train)\n","x_test = pad_sequences(sorted(x_test, key=len))\n","\n","split0 = int(len(x_test)/3)\n","split1 = int((2*len(x_test))/3)\n","print(split0,split1)\n","\n","#Test dataset small\n","x_test_small = x_test[:split0]\n","y_test_small = y_test[:split0]\n","\n","print(y_test_small.shape)\n","#Test dataset mid\n","x_test_mid = x_test[split0:split1]\n","y_test_mid = y_test[split0:split1]\n","\n","print(y_test_mid.shape)\n","#Test dataset large\n","x_test_large = x_test[split1:]\n","y_test_large = y_test[split1:]\n","\n","print(y_test_large.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKcT0MPSghns","executionInfo":{"status":"ok","timestamp":1665478862785,"user_tz":300,"elapsed":218,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"aef46766-641b-4819-8127-6eef92e27021"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["557 1114\n","(557,)\n","(557,)\n","(558,)\n"]}]},{"cell_type":"code","source":["##Debugging splits\n","print(x_test_small)\n","print(x_test_mid)\n","print(x_test_large)\n","\n","print(y_test_small)\n","print(y_test_mid)\n","print(y_test_large)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1CpiZBl2lTQ","executionInfo":{"status":"ok","timestamp":1665478866489,"user_tz":300,"elapsed":529,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"59897083-6e04-42e4-d536-22336fcbd50d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[[   0    0    0 ...    0    0  743]\n"," [   0    0    0 ...    0    0  570]\n"," [   0    0    0 ...    0    0  647]\n"," ...\n"," [   0    0    0 ... 6613    2 1210]\n"," [   0    0    0 ...    8    5 1289]\n"," [   0    0    0 ...  198   55   20]]\n","[[   0    0    0 ... 5098 5099    3]\n"," [   0    0    0 ...   86  569   44]\n"," [   0    0    0 ...   45 3869 1102]\n"," ...\n"," [   0    0    0 ...  283 3469  187]\n"," [   0    0    0 ...    2   32 2133]\n"," [   0    0    0 ...  154  655  847]]\n","[[   0    0    0 ...   29 4190  388]\n"," [   0    0    0 ...   15  810 8392]\n"," [   0    0    0 ...   17  108  196]\n"," ...\n"," [   0    0    0 ... 2640 1603  428]\n"," [   0    0    0 ...  132  249  811]\n"," [ 607  615   15 ... 1198  798 1373]]\n","83      0\n","2235    0\n","2746    0\n","246     0\n","3120    0\n","       ..\n","4051    0\n","3285    0\n","2885    0\n","3903    1\n","2103    0\n","Name: Target, Length: 557, dtype: int64\n","3412    0\n","4458    1\n","2748    0\n","1078    0\n","3205    0\n","       ..\n","5529    0\n","2460    0\n","2661    0\n","2086    0\n","5126    0\n","Name: Target, Length: 557, dtype: int64\n","2886    0\n","4459    0\n","1921    0\n","5255    0\n","5507    0\n","       ..\n","19      1\n","1344    0\n","2585    0\n","2928    0\n","891     0\n","Name: Target, Length: 558, dtype: int64\n"]}]},{"cell_type":"code","source":["#Metric definitions from Stack Overflow\n","def recall_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def precision_m(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def f1_m(y_true, y_pred):\n","    precision = precision_m(y_true, y_pred)\n","    recall = recall_m(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"metadata":{"id":"sTQg-oVyyFo5","executionInfo":{"status":"ok","timestamp":1665478879859,"user_tz":300,"elapsed":208,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["#Simple RNN\n","EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Embedding(len(tokenizer.word_index)+1, EMBEDDING_SIZE))\n","model.add(SimpleRNN(EMBEDDING_SIZE, input_shape=(X_train.shape[1],1)))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","\n","#Train and save the best model\n","filepath = \"SimpleRNN_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test_large, y_test_large, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExInf66yiCGJ","outputId":"b1463d98-3dab-4988-9135-fbe61cdafde2","executionInfo":{"status":"ok","timestamp":1665479109164,"user_tz":300,"elapsed":226340,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, None, 512)         4567552   \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 512)               524800    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 5,092,865\n","Trainable params: 5,092,865\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.8495 - f1_m: 0.0106 - precision_m: 0.0293 - recall_m: 0.0192\n","Epoch 1: loss improved from inf to 0.43913, saving model to SimpleRNN_model.h1\n","39/39 [==============================] - 45s 1s/step - loss: 0.4391 - accuracy: 0.8495 - f1_m: 0.0106 - precision_m: 0.0293 - recall_m: 0.0192\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.8651 - f1_m: 0.0064 - precision_m: 0.0513 - recall_m: 0.0034\n","Epoch 2: loss improved from 0.43913 to 0.40165, saving model to SimpleRNN_model.h1\n","39/39 [==============================] - 43s 1s/step - loss: 0.4016 - accuracy: 0.8651 - f1_m: 0.0064 - precision_m: 0.0513 - recall_m: 0.0034\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8605 - f1_m: 0.0625 - precision_m: 0.1598 - recall_m: 0.0470\n","Epoch 3: loss improved from 0.40165 to 0.35733, saving model to SimpleRNN_model.h1\n","39/39 [==============================] - 44s 1s/step - loss: 0.3573 - accuracy: 0.8605 - f1_m: 0.0625 - precision_m: 0.1598 - recall_m: 0.0470\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9059 - f1_m: 0.5483 - precision_m: 0.7306 - recall_m: 0.4582\n","Epoch 4: loss improved from 0.35733 to 0.22895, saving model to SimpleRNN_model.h1\n","39/39 [==============================] - 43s 1s/step - loss: 0.2289 - accuracy: 0.9059 - f1_m: 0.5483 - precision_m: 0.7306 - recall_m: 0.4582\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.9374 - f1_m: 0.7312 - precision_m: 0.8436 - recall_m: 0.6724\n","Epoch 5: loss improved from 0.22895 to 0.15523, saving model to SimpleRNN_model.h1\n","39/39 [==============================] - 44s 1s/step - loss: 0.1552 - accuracy: 0.9374 - f1_m: 0.7312 - precision_m: 0.8436 - recall_m: 0.6724\n","1/3 test data score\n","Test loss: 0.7050\n","Test accuracy: 84.20\n","Test f1_score: 0.03\n","Test precision: 0.06\n","Test recall: 0.02\n","2/3 test data score\n","Test loss: 0.5498\n","Test accuracy: 85.64\n","Test f1_score: 0.02\n","Test precision: 0.03\n","Test recall: 0.01\n","Full test data score\n","Test loss: 0.6758\n","Test accuracy: 83.13\n","Test f1_score: 0.03\n","Test precision: 0.05\n","Test recall: 0.03\n"]}]},{"cell_type":"code","source":["#LSTM\n","EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Embedding(len(tokenizer.word_index)+1, EMBEDDING_SIZE))\n","model.add(LSTM(EMBEDDING_SIZE, input_shape=(X_train.shape[1],1)))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","\n","#Train and save the best model\n","filepath = \"LSTM_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test_large, y_test_large, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"id":"dxmTFcp3yBZf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ae26826-435d-4d77-f5f9-d76df2be11f2","executionInfo":{"status":"ok","timestamp":1665480305221,"user_tz":300,"elapsed":960721,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_4 (Embedding)     (None, None, 512)         4567552   \n","                                                                 \n"," lstm_2 (LSTM)               (None, 512)               2099200   \n","                                                                 \n"," dropout_4 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 6,667,265\n","Trainable params: 6,667,265\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.8569 - f1_m: 0.0058 - precision_m: 0.0037 - recall_m: 0.0128\n","Epoch 1: loss improved from inf to 0.42724, saving model to LSTM_model.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6764a6fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 186s 5s/step - loss: 0.4272 - accuracy: 0.8569 - f1_m: 0.0058 - precision_m: 0.0037 - recall_m: 0.0128\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8672 - f1_m: 0.0085 - precision_m: 0.0513 - recall_m: 0.0047\n","Epoch 2: loss improved from 0.42724 to 0.36753, saving model to LSTM_model.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6764a6fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 185s 5s/step - loss: 0.3675 - accuracy: 0.8672 - f1_m: 0.0085 - precision_m: 0.0513 - recall_m: 0.0047\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.8915 - f1_m: 0.4202 - precision_m: 0.7456 - recall_m: 0.3149\n","Epoch 3: loss improved from 0.36753 to 0.26405, saving model to LSTM_model.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6764a6fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 184s 5s/step - loss: 0.2640 - accuracy: 0.8915 - f1_m: 0.4202 - precision_m: 0.7456 - recall_m: 0.3149\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9331 - f1_m: 0.7007 - precision_m: 0.8517 - recall_m: 0.6154\n","Epoch 4: loss improved from 0.26405 to 0.16935, saving model to LSTM_model.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6764a6fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 195s 5s/step - loss: 0.1694 - accuracy: 0.9331 - f1_m: 0.7007 - precision_m: 0.8517 - recall_m: 0.6154\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9541 - f1_m: 0.7983 - precision_m: 0.8693 - recall_m: 0.7547\n","Epoch 5: loss improved from 0.16935 to 0.12002, saving model to LSTM_model.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f6764a6fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 185s 5s/step - loss: 0.1200 - accuracy: 0.9541 - f1_m: 0.7983 - precision_m: 0.8693 - recall_m: 0.7547\n","1/3 test data score\n","Test loss: 0.6504\n","Test accuracy: 82.05\n","Test f1_score: 0.09\n","Test precision: 0.15\n","Test recall: 0.06\n","2/3 test data score\n","Test loss: 0.5772\n","Test accuracy: 82.76\n","Test f1_score: 0.05\n","Test precision: 0.07\n","Test recall: 0.04\n","Full test data score\n","Test loss: 0.6479\n","Test accuracy: 81.28\n","Test f1_score: 0.10\n","Test precision: 0.16\n","Test recall: 0.09\n"]}]},{"cell_type":"code","source":["#GRU\n","EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Embedding(len(tokenizer.word_index)+1, EMBEDDING_SIZE))\n","model.add(GRU(EMBEDDING_SIZE, input_shape=(X_train.shape[1],1)))\n","model.add(Dropout(0.3))\n","model.add(Dense(1, activation='sigmoid'))\n","model.summary()\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","\n","#Train and save the best model\n","filepath = \"GRU_model.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"3/3 test data score\")\n","score = model.evaluate(x_test_large, y_test_large, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"id":"8tt62jhbyVx4","executionInfo":{"status":"aborted","timestamp":1665479339978,"user_tz":300,"elapsed":9,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Part Two\n","\n","#Download and unzip the Stanford GloVe model (pretrained word embeddings)\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrMF2CNGIZHM","executionInfo":{"status":"ok","timestamp":1665428788972,"user_tz":300,"elapsed":186972,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"fdb3f612-07e5-4977-f054-7168bb4e6531"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-10 19:03:22--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2022-10-10 19:03:22--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2022-10-10 19:03:22--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 40s  \n","\n","2022-10-10 19:06:03 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"code","source":["!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n","!unzip -q glove.twitter.27B.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rKAAdOP0W5Kc","executionInfo":{"status":"ok","timestamp":1665430275655,"user_tz":300,"elapsed":337993,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"8d6e4721-68a8-491b-9232-0157119f344d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-10 19:25:38--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n","--2022-10-10 19:25:38--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1520408563 (1.4G) [application/zip]\n","Saving to: ‘glove.twitter.27B.zip’\n","\n","glove.twitter.27B.z 100%[===================>]   1.42G  5.10MB/s    in 4m 45s  \n","\n","2022-10-10 19:30:23 (5.08 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n","\n"]}]},{"cell_type":"code","source":["# Upgrade pip to the latest, and install TFMA.\n","!pip install -U pip\n","!pip install tensorflow-model-analysis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LLZPnkeSUbRs","executionInfo":{"status":"ok","timestamp":1665446170925,"user_tz":300,"elapsed":120709,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"c1bdbee0-540e-488f-cb28-a666e8525a9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 8.5 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-22.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-model-analysis\n","  Downloading tensorflow_model_analysis-0.41.1-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (7.9.0)\n","Requirement already satisfied: numpy<2,>=1.16 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.21.6)\n","Collecting attrs<22,>=19.3.0\n","  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipywidgets<8,>=7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (7.7.1)\n","Requirement already satisfied: pandas<2,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.3.5)\n","Requirement already satisfied: protobuf<4,>=3.13 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (3.17.3)\n","Requirement already satisfied: pyarrow<7,>=6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (6.0.1)\n","Requirement already satisfied: six<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.15.0)\n","Collecting tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5\n","  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-metadata<1.11.0,>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.10.0)\n","Collecting tfx-bsl<1.11.0,>=1.10.1\n","  Downloading tfx_bsl-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (21.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy<2,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.7.3)\n","Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-analysis) (1.2.0)\n","Collecting apache-beam[gcp]<3,>=2.40\n","  Downloading apache_beam-2.41.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n","  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (0.17.4)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (2.8.2)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.7)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (4.1.1)\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.3.0)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.1/508.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio<2,>=1.33.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.49.1)\n","Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (2022.4)\n","Collecting google-cloud-recommendations-ai<0.8.0,>=0.1.0\n","  Downloading google_cloud_recommendations_ai-0.7.1-py2.py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-spanner<2,>=1.13.0\n","  Downloading google_cloud_spanner-1.19.3-py2.py3-none-any.whl (255 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-language<2,>=1.3.0\n","  Downloading google_cloud_language-1.3.2-py2.py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-apitools<0.5.32,>=0.5.31\n","  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.5/173.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting google-auth-httplib2<0.2.0,>=0.1.0\n","  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: cachetools<5,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (4.2.4)\n","Collecting google-cloud-bigquery-storage<2.14,>=2.6.3\n","  Downloading google_cloud_bigquery_storage-2.13.2-py2.py3-none-any.whl (180 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-pubsub<3,>=2.1.0\n","  Downloading google_cloud_pubsub-2.13.9-py2.py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.7/236.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-cloud-core<3,>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.0.3)\n","Requirement already satisfied: google-api-core!=2.8.2,<3 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.31.6)\n","Collecting grpcio-gcp<1,>=0.2.2\n","  Downloading grpcio_gcp-0.2.2-py2.py3-none-any.whl (9.4 kB)\n","Collecting google-cloud-dlp<4,>=3.0.0\n","  Downloading google_cloud_dlp-3.9.2-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-videointelligence<2,>=1.8.0\n","  Downloading google_cloud_videointelligence-1.16.3-py2.py3-none-any.whl (183 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-bigtable<2,>=0.31.1\n","  Downloading google_cloud_bigtable-1.7.2-py2.py3-none-any.whl (267 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.7/267.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n","  Downloading google_cloud_vision-1.0.2-py2.py3-none-any.whl (435 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.1/435.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.21.0)\n","Requirement already satisfied: google-cloud-datastore<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.8.0)\n","Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.35.0)\n","Collecting google-cloud-pubsublite<2,>=1.2.0\n","  Downloading google_cloud_pubsublite-1.5.0-py2.py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (2.0.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (57.4.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (5.1.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (4.8.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=7->tensorflow-model-analysis) (4.4.2)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis) (3.6.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis) (3.0.3)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis) (0.2.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7->tensorflow-model-analysis) (5.3.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.1.2)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (0.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (21.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (2.0.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (14.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (22.9.24)\n","Collecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.1.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (0.27.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.14.1)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata<1.11.0,>=1.10.0->tensorflow-model-analysis) (1.56.4)\n","Collecting tensorflow-serving-api!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15\n","  Downloading tensorflow_serving_api-2.10.0-py2.py3-none-any.whl (37 kB)\n","Requirement already satisfied: google-api-python-client<2,>=1.7.11 in /usr/local/lib/python3.7/dist-packages (from tfx-bsl<1.11.0,>=1.10.1->tensorflow-model-analysis) (1.12.11)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (0.37.1)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.11.0,>=1.10.1->tensorflow-model-analysis) (3.0.1)\n","Collecting fasteners>=0.14\n","  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n","Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (4.1.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (4.9)\n","Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3,>=1.6.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (0.4.1)\n","Collecting protobuf<4,>=3.13\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpc-google-iam-v1<0.13dev,>=0.12.3\n","  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n","Collecting google-cloud-core<3,>=0.28.1\n","  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n","Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n","  Downloading google_api_core-1.33.2-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio-status>=1.16.0\n","  Downloading grpcio_status-1.49.1-py3-none-any.whl (14 kB)\n","Collecting overrides<7.0.0,>=6.0.1\n","  Downloading overrides-6.5.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.5.2)\n","Collecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis) (6.1.12)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython<8,>=7->tensorflow-model-analysis) (0.8.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.0.9)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis) (0.2.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (1.24.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (2022.9.24)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (2.1.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.0.1)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (5.3.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython<8,>=7->tensorflow-model-analysis) (0.7.0)\n","Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n","  Downloading google_api_core-1.33.1-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading google_api_core-1.33.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-api-core[grpc,grpcgcp] to determine which version is compatible with other requirements. This could take a while.\n","Collecting google-api-core[grpc,grpcgcp]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n","  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n","  Downloading google_api_core-2.10.1-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading google_api_core-2.9.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.8.1-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.8.0-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.7.3-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.7.2-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.7.1-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.7.0-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-api-core[grpc,grpcgcp] to determine which version is compatible with other requirements. This could take a while.\n","\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.6.1-py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n","\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.6.0-py2.py3-none-any.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.5.0-py2.py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.4.0-py2.py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0m  Downloading google_api_core-2.3.2-py2.py3-none-any.whl (109 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","\u001b[33mWARNING: google-api-core 2.8.2 does not provide the extra 'grpcgcp'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (1.3.1)\n","Collecting grpcio-status>=1.16.0\n","  Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (5.0.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (5.6.1)\n","Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (4.11.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (2.11.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (5.6.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7->tensorflow-model-analysis) (23.2.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.40->tensorflow-model-analysis) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5->tensorflow-model-analysis) (3.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (2.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (5.0.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.4)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.6.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (2.16.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (4.3.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (5.9.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7->tensorflow-model-analysis) (0.5.1)\n","Building wheels for collected packages: dill, google-apitools, docopt\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=8d6fb8889cb5f6c6c97eda9ea4cdff4c7bffdbd7aa2bad605310f5379f475ada\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131039 sha256=789c45e9677914f37f21f06cce46a693ca0bae93603f42bc72aae8ad0303d274\n","  Stored in directory: /root/.cache/pip/wheels/19/b5/2f/1cc3cf2b31e7a9cd1508731212526d9550271274d351c96f16\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=288af9af6afebc717a6f76f3e87f36470f3d9959f08a398a68e96aea2d3b9864\n","  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n","Successfully built dill google-apitools docopt\n","Installing collected packages: keras, docopt, tensorflow-estimator, requests, pymongo, protobuf, overrides, orjson, jedi, gast, fasteners, fastavro, dill, cloudpickle, attrs, proto-plus, hdfs, grpcio-gcp, grpcio-status, google-auth-httplib2, google-apitools, google-api-core, apache-beam, tensorboard, grpc-google-iam-v1, google-cloud-core, tensorflow, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-language, google-cloud-dlp, google-cloud-bigtable, google-cloud-bigquery-storage, tensorflow-serving-api, google-cloud-pubsublite, tfx-bsl, tensorflow-model-analysis\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.2.0\n","    Uninstalling pymongo-4.2.0:\n","      Successfully uninstalled pymongo-4.2.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.5.0\n","    Uninstalling cloudpickle-1.5.0:\n","      Successfully uninstalled cloudpickle-1.5.0\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 22.1.0\n","    Uninstalling attrs-22.1.0:\n","      Successfully uninstalled attrs-22.1.0\n","  Attempting uninstall: google-auth-httplib2\n","    Found existing installation: google-auth-httplib2 0.0.4\n","    Uninstalling google-auth-httplib2-0.0.4:\n","      Successfully uninstalled google-auth-httplib2-0.0.4\n","  Attempting uninstall: google-api-core\n","    Found existing installation: google-api-core 1.31.6\n","    Uninstalling google-api-core-1.31.6:\n","      Successfully uninstalled google-api-core-1.31.6\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: google-cloud-core\n","    Found existing installation: google-cloud-core 1.0.3\n","    Uninstalling google-cloud-core-1.0.3:\n","      Successfully uninstalled google-cloud-core-1.0.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.2+zzzcolab20220929150707\n","    Uninstalling tensorflow-2.8.2+zzzcolab20220929150707:\n","      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220929150707\n","  Attempting uninstall: google-cloud-language\n","    Found existing installation: google-cloud-language 1.2.0\n","    Uninstalling google-cloud-language-1.2.0:\n","      Successfully uninstalled google-cloud-language-1.2.0\n","  Attempting uninstall: google-cloud-bigquery-storage\n","    Found existing installation: google-cloud-bigquery-storage 1.1.2\n","    Uninstalling google-cloud-bigquery-storage-1.1.2:\n","      Successfully uninstalled google-cloud-bigquery-storage-1.1.2\n","Successfully installed apache-beam-2.41.0 attrs-21.4.0 cloudpickle-2.2.0 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.1 fasteners-0.18 gast-0.4.0 google-api-core-1.33.2 google-apitools-0.5.31 google-auth-httplib2-0.1.0 google-cloud-bigquery-storage-2.13.2 google-cloud-bigtable-1.7.2 google-cloud-core-1.7.3 google-cloud-dlp-3.9.2 google-cloud-language-1.3.2 google-cloud-pubsub-2.13.9 google-cloud-pubsublite-1.5.0 google-cloud-recommendations-ai-0.7.1 google-cloud-spanner-1.19.3 google-cloud-videointelligence-1.16.3 google-cloud-vision-1.0.2 grpc-google-iam-v1-0.12.4 grpcio-gcp-0.2.2 grpcio-status-1.48.2 hdfs-2.7.0 jedi-0.18.1 keras-2.10.0 orjson-3.8.0 overrides-6.5.0 proto-plus-1.22.1 protobuf-3.19.6 pymongo-3.12.3 requests-2.28.1 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-model-analysis-0.41.1 tensorflow-serving-api-2.10.0 tfx-bsl-1.10.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cloudpickle","dill","gast","google","google_auth_httplib2","keras","requests","tensorboard","tensorflow"]}}},"metadata":{}}]},{"cell_type":"code","source":["#Install Gensim\n","!pip install --upgrade gensim"],"metadata":{"id":"FpPvspM5lDjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665429351328,"user_tz":300,"elapsed":8972,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"4dcceba1-eec1-48a6-cdb0-e0cf914295f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Collecting gensim\n","  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[K     |████████████████████████████████| 24.1 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-4.2.0\n"]}]},{"cell_type":"code","source":["#2. Use builtin function in Gensim to convert glove to word2vec format\n","# Gensim works on Word2Vec and has built in function to convert Glove to Word2Vec\n","\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","glove_input_file = \"glove.6B.100d.txt\"\n","word2vec_output_file = \"glove.6B.100d.word2vec.txt\"\n","glove2word2vec(glove_input_file, word2vec_output_file)"],"metadata":{"id":"4L9D-01ulF1C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665450172576,"user_tz":300,"elapsed":62473,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"5f2d1dc4-7af2-4427-c6f4-7b8cbe20e69c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n","  import sys\n"]},{"output_type":"execute_result","data":{"text/plain":["(400000, 100)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["big_glove_input_file = \"glove.twitter.27B.100d.txt\"\n","big_word2vec_output_file = \"glove.twitter.27B.100d.word2vec.txt\"\n","glove2word2vec(big_glove_input_file, big_word2vec_output_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ek2JGjNwcwez","executionInfo":{"status":"ok","timestamp":1665450339349,"user_tz":300,"elapsed":166779,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"23470167-e596-40e8-d302-41e9cd4746ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"execute_result","data":{"text/plain":["(1193514, 100)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#10. Read the embeddings in the pretrained model \n","\n","import os\n","path_to_glove_file = \"glove.6B.100d.word2vec.txt\"\n","\n","embeddings_index = {}\n","\n","with open(path_to_glove_file) as f:\n","  for line in f:\n","    word, coefs = line.split(maxsplit = 1)\n","    coefs = np.fromstring(coefs, \"f\", sep = \" \")\n","    embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xFwF8xuNkzUs","executionInfo":{"status":"ok","timestamp":1665450346587,"user_tz":300,"elapsed":7264,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"351602cf-e329-41fa-c57e-6480f26bf784"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400001 word vectors.\n"]}]},{"cell_type":"code","source":["#11. Create \"embedding_matrix\" to index our vocab using the GloVe model\n","\n","# Prepare embedding_matrix for our word list\n","embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 100)) #Not \", EMBEDDING_SIZE\"?\n","for word, i in word_index.items():\n","  embedding_vector = embeddings_index.get(word)\n","  if embedding_vector is not None:\n","    embedding_matrix[i] = embedding_vector\n","\n","print(embedding_matrix.shape)"],"metadata":{"id":"shgEb3Suk0L9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Embedding again for the bigger Twitter model\n","\n","path_to_glove_file = \"glove.twitter.27B.100d.word2vec.txt\"\n","\n","big_embeddings_index = {}\n","\n","with open(path_to_glove_file) as f:\n","  for line in f:\n","    word, coefs = line.split(maxsplit = 1)\n","    coefs = np.fromstring(coefs, \"f\", sep = \" \")\n","    big_embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(big_embeddings_index))"],"metadata":{"id":"8SZtJvSJkkep","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665453428535,"user_tz":300,"elapsed":30918,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"fb5b846f-e576-4b2a-fd98-fadf9af2dc52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1193515 word vectors.\n"]}]},{"cell_type":"code","source":["# Creating \"embedding_matrix\" again to index our vocab using the bigger Twitter model\n","\n","# Prepare embedding_matrix for our word list\n","big_embedding_matrix = np.zeros((len(tokenizer.word_index)+1, 100)) #Not \", EMBEDDING_SIZE\"?\n","for word, i in word_index.items():\n","  big_embedding_vector = big_embeddings_index.get(word)\n","  if big_embedding_vector is not None:\n","    big_embedding_matrix[i] = big_embedding_vector\n","\n","print(embedding_matrix.shape)"],"metadata":{"id":"m5aweWGVkkTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Intermediary steps\n","\n","#vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=100)\n","#voc = vectorizer.get_vocabulary()\n","\n","## Prep the train dataset to samples and labels\n","#train_samples = [x['text'] for x in train]\n","#train_labels = [x['label'] for x in train]\n","#print(\"Classes: \", np.unique(train_labels))\n","#print(\"Number of samples in train: \", len(train_samples))\n","#print(train_samples[0])\n","\n","#val_samples = [x['text'] for x in val]\n","#val_labels = [x['label'] for x in val]\n","\n","#test_samples = [x['text'] for x in test]\n","#test_labels = [x['label'] for x in test]\n","\n","#vocab_size = len(tokenizer.word_index) + 1\n","print((X_train.shape[1],1))"],"metadata":{"id":"JHTxPhVz3Tzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Simple RNN - Glove 6B\n","#EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Input(shape=(None, ), dtype = \"int64\"))\n","model.add(Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=20, trainable=False))\n","model.add(SimpleRNN(100, input_shape=(X_train.shape[1],1)))\n","#model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","# summarize the model\n","model.summary()\n","\n","#Train and save the best model\n","filepath = \"SimpleRNN_glove_6B.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test, y_test, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","\n","print(\"Simple RNN - Glove 6B Confusion Matrix\")\n","#mat1 = metrics.confusion_matrix(y_test, x_test)\n","#sns.heatmap(mat1.T, square = True, annot = True, fmt = 'd', cbar = False)\n","#plt.xlabel(\"True label\")\n","#plt.ylabel(\"Predicted label\")\n","tfma.metrics.ConfusionMatrixPlot(\n","    num_thresholds: int = DEFAULT_NUM_THRESHOLDS,\n","    name: str = CONFUSION_MATRIX_PLOT_NAME\n",")"],"metadata":{"id":"-khEtZkHYJ_a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665453473576,"user_tz":300,"elapsed":68,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"4f8c15cc-dfb1-4545-e4cb-95e9f477f31f"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, None, 100)         892100    \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 100)               20100     \n","                                                                 \n"," flatten (Flatten)           (None, 100)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 912,301\n","Trainable params: 20,201\n","Non-trainable params: 892,100\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9085 - f1_m: 0.5865 - precision_m: 0.7744 - recall_m: 0.5364\n","Epoch 1: loss improved from inf to 0.24108, saving model to SimpleRNN_glove_6B.h1\n","39/39 [==============================] - 7s 137ms/step - loss: 0.2411 - accuracy: 0.9085 - f1_m: 0.5865 - precision_m: 0.7744 - recall_m: 0.5364\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9426 - f1_m: 0.7437 - precision_m: 0.8717 - recall_m: 0.6670\n","Epoch 2: loss improved from 0.24108 to 0.16517, saving model to SimpleRNN_glove_6B.h1\n","39/39 [==============================] - 6s 151ms/step - loss: 0.1652 - accuracy: 0.9426 - f1_m: 0.7437 - precision_m: 0.8717 - recall_m: 0.6670\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9692 - f1_m: 0.8784 - precision_m: 0.9305 - recall_m: 0.8542\n","Epoch 3: loss improved from 0.16517 to 0.09734, saving model to SimpleRNN_glove_6B.h1\n","39/39 [==============================] - 5s 138ms/step - loss: 0.0973 - accuracy: 0.9692 - f1_m: 0.8784 - precision_m: 0.9305 - recall_m: 0.8542\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9744 - f1_m: 0.8987 - precision_m: 0.9369 - recall_m: 0.8738\n","Epoch 4: loss improved from 0.09734 to 0.07702, saving model to SimpleRNN_glove_6B.h1\n","39/39 [==============================] - 5s 137ms/step - loss: 0.0770 - accuracy: 0.9744 - f1_m: 0.8987 - precision_m: 0.9369 - recall_m: 0.8738\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.9662 - f1_m: 0.8702 - precision_m: 0.8948 - recall_m: 0.8657\n","Epoch 5: loss did not improve from 0.07702\n","39/39 [==============================] - 3s 82ms/step - loss: 0.0982 - accuracy: 0.9662 - f1_m: 0.8702 - precision_m: 0.8948 - recall_m: 0.8657\n","1/3 test data score\n","Test loss: 0.0985\n","Test accuracy: 96.23\n","Test f1_score: 0.84\n","Test precision: 0.92\n","Test recall: 0.82\n","2/3 test data score\n","Test loss: 0.0822\n","Test accuracy: 97.04\n","Test f1_score: 0.86\n","Test precision: 0.93\n","Test recall: 0.85\n","Full test data score\n","Test loss: 0.0886\n","Test accuracy: 97.07\n","Test f1_score: 0.87\n","Test precision: 0.93\n","Test recall: 0.85\n","Simple RNN - Glove 6B Confusion Matrix\n"]}]},{"cell_type":"code","source":["#LSTM - Glove 6B\n","#EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Input(shape=(None, ), dtype = \"int64\"))\n","model.add(Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=20, trainable=False))\n","model.add(LSTM(100, input_shape=(X_train.shape[1],1)))\n","#model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","# summarize the model\n","model.summary()\n","\n","#Train and save the best model\n","filepath = \"LSTM_glove_6B.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test, y_test, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJUIbtGibVvG","executionInfo":{"status":"ok","timestamp":1665441361540,"user_tz":300,"elapsed":149904,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"d9deb1aa-4361-4366-b23d-8e646abb8f3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_17\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_17 (Embedding)    (None, None, 100)         892100    \n","                                                                 \n"," lstm_3 (LSTM)               (None, 100)               80400     \n","                                                                 \n"," flatten_11 (Flatten)        (None, 100)               0         \n","                                                                 \n"," dense_16 (Dense)            (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 972,601\n","Trainable params: 80,501\n","Non-trainable params: 892,100\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.9018 - f1_m: 0.4070 - precision_m: 0.5403 - recall_m: 0.3567\n","Epoch 1: loss improved from inf to 0.26251, saving model to LSTM_glove_6B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa2173a8690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 20s 445ms/step - loss: 0.2625 - accuracy: 0.9018 - f1_m: 0.4070 - precision_m: 0.5403 - recall_m: 0.3567\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9703 - f1_m: 0.8806 - precision_m: 0.9062 - recall_m: 0.8724\n","Epoch 2: loss improved from 0.26251 to 0.09470, saving model to LSTM_glove_6B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa2173a8690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 18s 456ms/step - loss: 0.0947 - accuracy: 0.9703 - f1_m: 0.8806 - precision_m: 0.9062 - recall_m: 0.8724\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9785 - f1_m: 0.9107 - precision_m: 0.9168 - recall_m: 0.9112\n","Epoch 3: loss improved from 0.09470 to 0.06817, saving model to LSTM_glove_6B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa2173a8690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 17s 441ms/step - loss: 0.0682 - accuracy: 0.9785 - f1_m: 0.9107 - precision_m: 0.9168 - recall_m: 0.9112\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9813 - f1_m: 0.9240 - precision_m: 0.9368 - recall_m: 0.9194\n","Epoch 4: loss improved from 0.06817 to 0.05681, saving model to LSTM_glove_6B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa2173a8690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 18s 454ms/step - loss: 0.0568 - accuracy: 0.9813 - f1_m: 0.9240 - precision_m: 0.9368 - recall_m: 0.9194\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9869 - f1_m: 0.9471 - precision_m: 0.9565 - recall_m: 0.9424\n","Epoch 5: loss improved from 0.05681 to 0.04302, saving model to LSTM_glove_6B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa2173a8690> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 17s 442ms/step - loss: 0.0430 - accuracy: 0.9869 - f1_m: 0.9471 - precision_m: 0.9565 - recall_m: 0.9424\n","1/3 test data score\n","Test loss: 0.0526\n","Test accuracy: 98.20\n","Test f1_score: 0.93\n","Test precision: 0.95\n","Test recall: 0.93\n","2/3 test data score\n","Test loss: 0.0480\n","Test accuracy: 98.47\n","Test f1_score: 0.93\n","Test precision: 0.94\n","Test recall: 0.94\n","Full test data score\n","Test loss: 0.0555\n","Test accuracy: 98.21\n","Test f1_score: 0.92\n","Test precision: 0.94\n","Test recall: 0.93\n"]}]},{"cell_type":"code","source":["#Simple RNN - Glove 27B\n","#EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Input(shape=(None, ), dtype = \"int64\"))\n","model.add(Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=20, trainable=False))\n","model.add(SimpleRNN(100, input_shape=(X_train.shape[1],1)))\n","#model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","# summarize the model\n","model.summary()\n","\n","#Train and save the best model\n","filepath = \"SimpleRNN_glove_27B.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test, y_test, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lf_j73ribd3Q","executionInfo":{"status":"ok","timestamp":1665441406153,"user_tz":300,"elapsed":44641,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"e7785a4f-9a96-4ff2-ac1e-1edaaa2057c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_18\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_18 (Embedding)    (None, None, 100)         892100    \n","                                                                 \n"," simple_rnn_12 (SimpleRNN)   (None, 100)               20100     \n","                                                                 \n"," flatten_12 (Flatten)        (None, 100)               0         \n","                                                                 \n"," dense_17 (Dense)            (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 912,301\n","Trainable params: 20,201\n","Non-trainable params: 892,100\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.9028 - f1_m: 0.5026 - precision_m: 0.7669 - recall_m: 0.4244\n","Epoch 1: loss improved from inf to 0.25203, saving model to SimpleRNN_glove_27B.h1\n","39/39 [==============================] - 6s 130ms/step - loss: 0.2520 - accuracy: 0.9028 - f1_m: 0.5026 - precision_m: 0.7669 - recall_m: 0.4244\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9597 - f1_m: 0.8245 - precision_m: 0.8846 - recall_m: 0.7880\n","Epoch 2: loss improved from 0.25203 to 0.11327, saving model to SimpleRNN_glove_27B.h1\n","39/39 [==============================] - 5s 130ms/step - loss: 0.1133 - accuracy: 0.9597 - f1_m: 0.8245 - precision_m: 0.8846 - recall_m: 0.7880\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9749 - f1_m: 0.8944 - precision_m: 0.9293 - recall_m: 0.8720\n","Epoch 3: loss improved from 0.11327 to 0.08128, saving model to SimpleRNN_glove_27B.h1\n","39/39 [==============================] - 5s 132ms/step - loss: 0.0813 - accuracy: 0.9749 - f1_m: 0.8944 - precision_m: 0.9293 - recall_m: 0.8720\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9810 - f1_m: 0.9284 - precision_m: 0.9454 - recall_m: 0.9177\n","Epoch 4: loss improved from 0.08128 to 0.06551, saving model to SimpleRNN_glove_27B.h1\n","39/39 [==============================] - 6s 143ms/step - loss: 0.0655 - accuracy: 0.9810 - f1_m: 0.9284 - precision_m: 0.9454 - recall_m: 0.9177\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9826 - f1_m: 0.9307 - precision_m: 0.9468 - recall_m: 0.9189\n","Epoch 5: loss improved from 0.06551 to 0.05526, saving model to SimpleRNN_glove_27B.h1\n","39/39 [==============================] - 5s 133ms/step - loss: 0.0553 - accuracy: 0.9826 - f1_m: 0.9307 - precision_m: 0.9468 - recall_m: 0.9189\n","1/3 test data score\n","Test loss: 0.0542\n","Test accuracy: 97.85\n","Test f1_score: 0.93\n","Test precision: 0.96\n","Test recall: 0.92\n","2/3 test data score\n","Test loss: 0.0505\n","Test accuracy: 98.20\n","Test f1_score: 0.93\n","Test precision: 0.95\n","Test recall: 0.93\n","Full test data score\n","Test loss: 0.0658\n","Test accuracy: 97.67\n","Test f1_score: 0.91\n","Test precision: 0.94\n","Test recall: 0.91\n"]}]},{"cell_type":"code","source":["#LSTM - Glove 27B\n","#EMBEDDING_SIZE=512\n","model = keras.Sequential()\n","model.add(Input(shape=(None, ), dtype = \"int64\"))\n","model.add(Embedding(len(tokenizer.word_index) + 1, 100, weights=[embedding_matrix], input_length=20, trainable=False))\n","model.add(LSTM(100, input_shape=(X_train.shape[1],1)))\n","#model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","# compile the model\n","model.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics = [\"accuracy\", f1_m, precision_m, recall_m])\n","# summarize the model\n","model.summary()\n","\n","#Train and save the best model\n","filepath = \"LSTM_glove_27B.h1\"\n","checkpoint = ModelCheckpoint(filepath, monitor = \"loss\", mode = \"min\", verbose =1, save_best_only = True)\n","history = model.fit(X_train, Y_train, epochs = 5, batch_size = 100, callbacks = [checkpoint])\n","\n","#1/3 of test data\n","print(\"1/3 test data score\")\n","score = model.evaluate(x_test_small, y_test_small, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#2/3 of test data\n","print(\"2/3 test data score\")\n","score = model.evaluate(x_test_mid, y_test_mid, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))\n","\n","#3/3 of test data\n","print(\"Full test data score\")\n","score = model.evaluate(x_test, y_test, verbose = 0)\n","print(\"Test loss: %.4f\" % score[0])\n","print(\"Test accuracy: %.2f\" % (score[1] * 100.0))\n","print(\"Test f1_score: %.2f\" % (score[2]))\n","print(\"Test precision: %.2f\" % (score[3]))\n","print(\"Test recall: %.2f\" % (score[4]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qn8b5YwZbhHj","executionInfo":{"status":"ok","timestamp":1665442353378,"user_tz":300,"elapsed":149687,"user":{"displayName":"Mitchell Allen","userId":"05636341364452479839"}},"outputId":"7520dc52-6bf3-4be0-de12-9f784746926a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_20\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_20 (Embedding)    (None, None, 100)         892100    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 100)               80400     \n","                                                                 \n"," flatten_14 (Flatten)        (None, 100)               0         \n","                                                                 \n"," dense_19 (Dense)            (None, 1)                 101       \n","                                                                 \n","=================================================================\n","Total params: 972,601\n","Trainable params: 80,501\n","Non-trainable params: 892,100\n","_________________________________________________________________\n","Epoch 1/5\n","39/39 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.8615 - f1_m: 0.2936 - precision_m: 0.4336 - recall_m: 0.2631\n","Epoch 1: loss improved from inf to 0.30708, saving model to LSTM_glove_27B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa21f03d3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 20s 457ms/step - loss: 0.3071 - accuracy: 0.8615 - f1_m: 0.2936 - precision_m: 0.4336 - recall_m: 0.2631\n","Epoch 2/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9718 - f1_m: 0.8915 - precision_m: 0.9031 - recall_m: 0.8901\n","Epoch 2: loss improved from 0.30708 to 0.09584, saving model to LSTM_glove_27B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa21f03d3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 17s 452ms/step - loss: 0.0958 - accuracy: 0.9718 - f1_m: 0.8915 - precision_m: 0.9031 - recall_m: 0.8901\n","Epoch 3/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9772 - f1_m: 0.9096 - precision_m: 0.9229 - recall_m: 0.9060\n","Epoch 3: loss improved from 0.09584 to 0.07086, saving model to LSTM_glove_27B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa21f03d3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 18s 457ms/step - loss: 0.0709 - accuracy: 0.9772 - f1_m: 0.9096 - precision_m: 0.9229 - recall_m: 0.9060\n","Epoch 4/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 0.9797 - f1_m: 0.9191 - precision_m: 0.9237 - recall_m: 0.9202\n","Epoch 4: loss improved from 0.07086 to 0.06076, saving model to LSTM_glove_27B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa21f03d3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 19s 490ms/step - loss: 0.0608 - accuracy: 0.9797 - f1_m: 0.9191 - precision_m: 0.9237 - recall_m: 0.9202\n","Epoch 5/5\n","39/39 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.9859 - f1_m: 0.9483 - precision_m: 0.9668 - recall_m: 0.9367\n","Epoch 5: loss improved from 0.06076 to 0.04770, saving model to LSTM_glove_27B.h1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fa21f03d3d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r39/39 [==============================] - 17s 441ms/step - loss: 0.0477 - accuracy: 0.9859 - f1_m: 0.9483 - precision_m: 0.9668 - recall_m: 0.9367\n","1/3 test data score\n","Test loss: 0.0541\n","Test accuracy: 98.56\n","Test f1_score: 0.95\n","Test precision: 0.97\n","Test recall: 0.94\n","2/3 test data score\n","Test loss: 0.0495\n","Test accuracy: 98.74\n","Test f1_score: 0.95\n","Test precision: 0.95\n","Test recall: 0.96\n","Full test data score\n","Test loss: 0.0564\n","Test accuracy: 98.44\n","Test f1_score: 0.94\n","Test precision: 0.95\n","Test recall: 0.94\n"]}]}]}